{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1908a9c2-31de-46ba-b461-fa81f515487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import s3fs\n",
    "from aicsimageio.writers import OmeZarrWriter\n",
    "from aicsimageio import AICSImage\n",
    "from aicsimageio.dimensions import DimensionNames, DEFAULT_CHUNK_DIMS\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5001be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up some initial vars to find our data and where to put it\n",
    "\n",
    "filepath = \"my/path/to/data/file.tif\"\n",
    "output_filename = \"my_filename\"\n",
    "output_bucket = \"my_bucket\"\n",
    "# aws config\n",
    "os.environ[\"AWS_PROFILE\"] = \"my_creds\"\n",
    "os.environ[\"AWS_DEFAULT_REGION\"] = \"us-west-2\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8847835-b420-48b1-9df2-09078e9a9b05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# allow for dask parallelism\n",
    "from distributed import LocalCluster, Client\n",
    "cluster = LocalCluster(n_workers=4, processes=True, threads_per_worker=1)\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561c6a3d-8501-41c2-982b-a546d0e6c814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our image\n",
    "\n",
    "chunk_dims= [\n",
    "    DimensionNames.SpatialY,\n",
    "    DimensionNames.SpatialX,\n",
    "    DimensionNames.Samples,\n",
    "]\n",
    "img = AICSImage(filepath, chunk_dims=chunk_dims)\n",
    "\n",
    "# print some data about the image we loaded\n",
    "scenes = img.scenes\n",
    "print(scenes)\n",
    "print(str(len(scenes)))\n",
    "print(img.channel_names)\n",
    "print(img.physical_pixel_sizes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce00837-9e95-459c-9512-0fef22d896e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct some per-channel lists to feed in to the writer.\n",
    "# hardcoding to 9 for now\n",
    "channel_colors = [0xff0000, 0x00ff00, 0x0000ff, 0xffff00, 0xff00ff, 0x00ffff, 0x880000, 0x008800, 0x000088]\n",
    "\n",
    "# initialize for writing direct to S3\n",
    "s3 = s3fs.S3FileSystem(anon=False, config_kwargs={\"connect_timeout\": 60})\n",
    "\n",
    "def write_scene(storeroot, scenename, sceneindex, img):\n",
    "    print(scenename)\n",
    "    print(storeroot)\n",
    "    img.set_scene(sceneindex)\n",
    "    pps = img.physical_pixel_sizes\n",
    "    cn = img.channel_names\n",
    "\n",
    "    data = img.get_image_dask_data(\"TCZYX\")\n",
    "    print(data.shape)\n",
    "    writer = OmeZarrWriter(storeroot)\n",
    "\n",
    "    writer.write_image(\n",
    "        image_data=data,\n",
    "        image_name=scenename,\n",
    "        physical_pixel_sizes=pps,\n",
    "        channel_names=cn,\n",
    "        channel_colors=channel_colors,\n",
    "        scale_num_levels=4,\n",
    "        scale_factor=2.0,\n",
    "    )    \n",
    "\n",
    "# here we are splitting multi-scene images into separate zarr images based on scene name\n",
    "scene_indices = range(len(img.scenes))\n",
    "\n",
    "for i in scene_indices:\n",
    "    scenename = img.scenes[i]\n",
    "    scenename = scenename.replace(\":\",\"_\")\n",
    "    write_scene(f\"s3://{output_bucket}/{output_filename}/{scenename}.zarr/\", scenename, i, img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddfd030",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# READ BACK\n",
    "#############################################\n",
    "from ome_zarr.reader import Multiscales, Reader\n",
    "from ome_zarr.io import parse_url\n",
    "\n",
    "s3 = s3fs.S3FileSystem()\n",
    "mypath = f\"s3://{output_bucket}/{output_filename}/{scenes[scene_indices[0]]}.zarr\" \n",
    "\n",
    "reader = Reader(parse_url(mypath))\n",
    "node = list(reader())[0]\n",
    "# levels\n",
    "print(len(node.data))\n",
    "for i in range(len(node.data)):\n",
    "    print(f\"shape of level {i} : {node.data[i].shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bff414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbvv\n",
    "level = 1\n",
    "levelxyscale = 2**(level+1)\n",
    "t = 0\n",
    "readdata = node.data[level][t][0:2].compute()\n",
    "print(readdata.shape)\n",
    "nbvv.volshow(readdata, spacing=(img.physical_pixel_sizes.X*levelxyscale,\n",
    "        img.physical_pixel_sizes.Y*levelxyscale,\n",
    "        img.physical_pixel_sizes.Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5765d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": true,
  "vscode": {
   "interpreter": {
    "hash": "acd95a8530237d9a6e58775572ad6f18eaa27400a7c3d8072e8f8672de94478f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
